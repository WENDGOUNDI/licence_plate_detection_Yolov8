{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1aca5f6",
   "metadata": {},
   "source": [
    "## Train Yolov8 Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b92aafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\yolov8_anpr_al_pr\\dataset\\train\\labels... 182 images, 0 backgrounds, 0 corrupt: 100%|██████████| 182\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\yolov8_anpr_al_pr\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\yolov8_anpr_al_pr\\dataset\\val\\labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\yolov8_anpr_al_pr\\dataset\\val\\labels.cache\n",
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G      1.315        3.7       1.37         15        640: 100%|██████████| 12/12 [01:42<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24    0.00288      0.792      0.113     0.0509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      1.093      2.883      1.128         12        640: 100%|██████████| 12/12 [01:35<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24    0.00318      0.875      0.533      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G      1.051       1.86      1.108          9        640: 100%|██████████| 12/12 [01:35<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24    0.00333      0.917      0.711      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         0G      1.116      1.582      1.041          8        640: 100%|██████████| 12/12 [01:33<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24    0.00333      0.917      0.783      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         0G      1.142      1.374      1.047          8        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24    0.00333      0.917      0.845      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50         0G      1.157       1.26      1.034          9        640: 100%|██████████| 12/12 [01:26<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.253      0.874       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50         0G      1.139      1.154      1.067         18        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.583      0.791       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50         0G      1.207      1.209      1.088          9        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1        0.8      0.871       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50         0G      1.221       1.25      1.113         20        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.852      0.792      0.881      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50         0G      1.116      1.172      1.096         21        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.923      0.792      0.881      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50         0G      1.149      1.091       1.07         13        640: 100%|██████████| 12/12 [01:22<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.744      0.801      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50         0G      1.122      1.062      1.073         10        640: 100%|██████████| 12/12 [01:22<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.839      0.868      0.844      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50         0G      1.128      1.084        1.1         12        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.863      0.789      0.854      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50         0G      1.096       1.02      1.054         16        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.789      0.842      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50         0G      1.106       1.01      1.064         12        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.921       0.75      0.889      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50         0G      1.152     0.9629      1.112         16        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.833       0.93      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50         0G      1.055     0.9212      1.073         16        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24       0.95      0.791      0.907      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50         0G     0.9775     0.8786       1.03         10        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.954      0.855      0.927      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50         0G      1.019     0.8585      1.051         16        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.778      0.792      0.859      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50         0G      1.006     0.8597      1.035         10        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.879      0.917      0.938      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50         0G     0.9976     0.8094      1.023         16        640: 100%|██████████| 12/12 [01:25<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.989      0.792      0.904      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50         0G      1.001      0.849      1.037         17        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.829      0.943      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50         0G      1.014     0.8502      1.039         20        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.953      0.917      0.957      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50         0G     0.9649     0.7869      1.017         12        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24       0.95      0.958       0.98      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50         0G     0.9487     0.7725      1.014         11        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.831      0.905      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50         0G     0.9243     0.7494      1.015          9        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.992      0.833      0.925      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50         0G     0.9445      0.743     0.9936         11        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.997      0.875      0.923       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50         0G     0.9834     0.7728      1.013         12        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.988      0.875      0.909       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50         0G     0.9233     0.7237     0.9794         16        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.992      0.875      0.904      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50         0G     0.8553      0.688     0.9827         16        640: 100%|██████████| 12/12 [01:24<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.996      0.833      0.892      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50         0G     0.8718     0.7062     0.9684         13        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.988      0.833      0.908      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50         0G     0.8707     0.6949     0.9784          8        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.954      0.871      0.881      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50         0G     0.8524     0.6451     0.9722         10        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.913      0.875      0.881      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50         0G     0.8692     0.6708     0.9554         18        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.952      0.829      0.878      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50         0G     0.8734     0.6487     0.9722         18        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.785      0.874      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50         0G     0.8176     0.6183      0.963         15        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.979      0.875      0.878      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50         0G     0.8005     0.6547     0.9646          6        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.996      0.875       0.88      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50         0G     0.7617     0.5932     0.9578         14        640: 100%|██████████| 12/12 [01:23<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.991      0.875      0.885      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50         0G     0.7789     0.6074     0.9687         11        640: 100%|██████████| 12/12 [01:29<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24      0.996      0.917      0.937      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50         0G     0.7326     0.5633     0.9427         15        640: 100%|██████████| 12/12 [01:34<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.951      0.917      0.939      0.673\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50         0G     0.6997     0.6319     0.9241          6        640: 100%|██████████| 12/12 [01:27<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.956      0.914      0.925      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50         0G     0.7133     0.6252      0.908          7        640: 100%|██████████| 12/12 [01:53<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24      0.956      0.911      0.921       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50         0G     0.6953      0.587     0.9205          6        640: 100%|██████████| 12/12 [01:52<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n",
      "                   all         22         24          1      0.913      0.948      0.695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50         0G      0.682     0.5548     0.8887          6        640: 100%|██████████| 12/12 [01:56<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24          1      0.912      0.955      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50         0G      0.666     0.5611     0.8844          6        640: 100%|██████████| 12/12 [01:38<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<0\n",
      "                   all         22         24      0.995      0.875      0.954      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50         0G     0.6594     0.5447     0.8869          6        640: 100%|██████████| 12/12 [01:38<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<0\n",
      "                   all         22         24      0.996      0.875      0.956      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50         0G      0.667     0.5561     0.8776          6        640: 100%|██████████| 12/12 [01:32<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24      0.957      0.924      0.966      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50         0G     0.6448     0.5451     0.8732          6        640: 100%|██████████| 12/12 [01:20<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.914      0.965      0.695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50         0G     0.5888       0.53     0.8768          6        640: 100%|██████████| 12/12 [01:19<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n",
      "                   all         22         24          1      0.954      0.962      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50         0G     0.5959     0.5184     0.8956          6        640: 100%|██████████| 12/12 [01:29<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<0\n",
      "                   all         22         24          1      0.954      0.962      0.714\n",
      "\n",
      "50 epochs completed in 1.292 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Dataset 'data.yml' for task=detect not found ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23736\\2488631090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yolov8n.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data.yml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[1;31m# attach optional HUB session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# update model and cfg after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRANK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[1;34m(self, rank, world_size)\u001b[0m\n\u001b[0;32m    374\u001b[0m             LOGGER.info(f'\\n{epoch - self.start_epoch + 1} epochs completed in '\n\u001b[0;32m    375\u001b[0m                         f'{(time.time() - self.train_time_start) / 3600:.3f} hours.')\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36mfinal_eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    509\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                     \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nValidating {f}...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_fit_epoch_end'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_File\\anaconda3\\envs\\paddleocr\\lib\\site-packages\\ultralytics\\yolo\\engine\\validator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cls_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Dataset '{self.args.data}' for task={self.args.task} not found ❌\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Dataset 'data.yml' for task=detect not found "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "#model = YOLO()\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "# the data.yaml file \n",
    "model.train(data='data.yaml', epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a07de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\yolov8_anpr_al_pr\\dataset\\val\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|##########| 22/22 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\yolov8_anpr_al_pr\\dataset\\val\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|##########| 22/22 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:03<00:03,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:05<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:05<00:00,  2.55s/it]\n",
      "                   all         22         24      0.999      0.917      0.945      0.697\n",
      "Speed: 2.3ms preprocess, 189.5ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Validate our model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "!yolo task=detect mode=val model=\"runs/detect/train/weights/best.pt\" data=\"data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f4ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 D:\\yolov8_anpr_al_pr\\dataset\\test\\images\\N204.jpeg: 448x640 1 license_plate, 135.0ms\n",
      "Speed: 1.0ms preprocess, 135.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "## Predict / Test our model\n",
    "\n",
    "!yolo task=detect mode=predict model=\"D:/yolov8_anpr_alpr/runs/detect/train/weights/best.pt\" conf=0.25 source=\"dataset/test/images/N204.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4b901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 D:\\yolov8_anpr_al_pr\\test_image.jpg: 384x640 (no detections), 97.0ms\n",
      "Speed: 0.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"D:/yolov8_anpr_alpr/runs/detect/train/weights/best.pt\" conf=0.25 source=\"test_image.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4922ba5",
   "metadata": {},
   "source": [
    "## Test on Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49af0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b961d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 D:\\yolov8_anpr_alpr\\test_license_plate.jpg: 384x640 2 license_plates, 334.0ms\n",
      "Speed: 2.0ms preprocess, 334.0ms inference, 66.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Verify if the folder used to save extracted licence plate is present, otherwise create it\n",
    "Path(\"cropped_license_plates/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO(\"yolov8n.pt\")  # load an official model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # load a custom model\n",
    "test_image = \"test_license_plate.jpg\"\n",
    "# Predict with the model\n",
    "results = model(test_image, save=True, conf=.3)\n",
    "res = list(results)[0] # get result from generator\n",
    "#res.boxes    # or res[0]\n",
    "#res.masks  # or res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf7ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[510.0, 254.0, 615.0, 285.0], [76.0, 254.0, 172.0, 286.0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get coordinates from yolov8 detection and convert from torch tensor to list\n",
    "#coord = res.boxes[0].xyxy\n",
    "coord = res.boxes.xyxy\n",
    "coord = coord.tolist()\n",
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e5849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510.0, 254.0, 615.0, 285.0]\n",
      "[76.0, 254.0, 172.0, 286.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean the folder used for saving detected plates\n",
    "files = glob.glob('cropped_license_plates/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# Save the detected license plates\n",
    "count = 0\n",
    "for i in coord:\n",
    "    print(i)\n",
    "    \n",
    "    x1 = int(i[0])\n",
    "    y1 = int(i[1])\n",
    "    x2 = int(i[2])\n",
    "    y2 = int(i[3])\n",
    "\n",
    "    img = cv2.imread(test_image)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    #crop_img = img[x:x+h, y:y+w]\n",
    "    name = f\"cropped_license_plates/license_plate_{count}.jpg\"\n",
    "    cv2.imwrite(name, roi)\n",
    "    #cv2.imshow(\"cropped\", roi)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a53e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_license_plates\\license_plate_0.jpg\n",
      "JKO1T7347\n",
      "\n",
      "\n",
      "cropped_license_plates\\license_plate_1.jpg\n",
      "JKO1T7347\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OCR for license place content extraction\n",
    "for lp in glob.glob(\"cropped_license_plates/*.jpg\"):\n",
    "    print(lp)\n",
    "    img_path1 = lp\n",
    "    ocr_model = PaddleOCR(lang='en', show_log=False, use_angle_cls=True, use_gpu=False)\n",
    "    result = ocr_model.ocr(img_path1, cls=True)\n",
    "    for line in result:\n",
    "        print(line[1][0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21265ca",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a323aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def licence_plate_extraction(model, image):\n",
    "    # Load a model\n",
    "    model = YOLO(model)  # load a custom model\n",
    "    # Predict with the model\n",
    "    results = model(image, save=True, conf=.3)\n",
    "    res = list(results)[0] # get result from generator\n",
    "    \n",
    "    # get coordinates from yolov8 detection and convert from torch tensor to list\n",
    "    coord = res.boxes.xyxy\n",
    "    coord = coord.tolist()\n",
    "    \n",
    "    # Clean the folder used for saving previous detected plates\n",
    "    files = glob.glob('cropped_license_plates/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "    # Save the detected license plates\n",
    "    count = 0\n",
    "    for i in coord:\n",
    "        \n",
    "        x1 = int(i[0])\n",
    "        y1 = int(i[1])\n",
    "        x2 = int(i[2])\n",
    "        y2 = int(i[3])\n",
    "\n",
    "        img = cv2.imread(image)\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        name = f\"cropped_license_plates/license_plate_{count}.jpg\"\n",
    "        cv2.imwrite(name, roi)\n",
    "        count+=1\n",
    "        \n",
    "    # PaddleOCR for license place content extraction\n",
    "    for lp in glob.glob(\"cropped_license_plates/*.jpg\"):\n",
    "        ocr_model = PaddleOCR(lang='en', show_log=False, use_angle_cls=True, use_gpu=False)\n",
    "        result = ocr_model.ocr(lp, cls=True)\n",
    "        for line in result:\n",
    "            print(f\" Licence Plate: {line[1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13f598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.48  Python-3.7.10 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 D:\\yolov8_anpr_alpr\\test_license_plate.jpg: 384x640 2 license_plates, 137.0ms\n",
      "Speed: 1.0ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Licence Plate: JKO1T7347\n",
      " Licence Plate: JKO1T7347\n"
     ]
    }
   ],
   "source": [
    "model = \"runs/detect/train/weights/best.pt\"\n",
    "licence_image = \"test_license_plate.jpg\"\n",
    "\n",
    "licence_plate_extraction(model, licence_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
